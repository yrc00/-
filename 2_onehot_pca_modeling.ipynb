{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding + PCA Data Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시계열 데이터를 one-hot encoding\n",
    "- PCA 피처를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.327</td>\n",
       "      <td>12.250</td>\n",
       "      <td>-3.294</td>\n",
       "      <td>-7.855</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>13.824</td>\n",
       "      <td>-10.249</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-5.170</td>\n",
       "      <td>8.077</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.616525</td>\n",
       "      <td>-2.341176</td>\n",
       "      <td>-3.016174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.267</td>\n",
       "      <td>12.916</td>\n",
       "      <td>-3.220</td>\n",
       "      <td>-7.788</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>14.424</td>\n",
       "      <td>-10.249</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-4.970</td>\n",
       "      <td>8.027</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.691167</td>\n",
       "      <td>-2.187795</td>\n",
       "      <td>-3.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.127</td>\n",
       "      <td>13.583</td>\n",
       "      <td>-3.130</td>\n",
       "      <td>-7.658</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>15.081</td>\n",
       "      <td>-10.359</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-4.830</td>\n",
       "      <td>7.977</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.724164</td>\n",
       "      <td>-2.076864</td>\n",
       "      <td>-2.954282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.060</td>\n",
       "      <td>14.250</td>\n",
       "      <td>-3.130</td>\n",
       "      <td>-7.532</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>14.961</td>\n",
       "      <td>-10.359</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-4.830</td>\n",
       "      <td>7.927</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.744811</td>\n",
       "      <td>-2.076954</td>\n",
       "      <td>-2.864929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.967</td>\n",
       "      <td>14.916</td>\n",
       "      <td>-3.094</td>\n",
       "      <td>-7.462</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>15.454</td>\n",
       "      <td>-10.359</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-4.970</td>\n",
       "      <td>7.877</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.827777</td>\n",
       "      <td>-1.960836</td>\n",
       "      <td>-2.942832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.967</td>\n",
       "      <td>15.583</td>\n",
       "      <td>-3.020</td>\n",
       "      <td>-7.388</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>15.284</td>\n",
       "      <td>-10.419</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-4.860</td>\n",
       "      <td>7.827</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.914471</td>\n",
       "      <td>-1.906830</td>\n",
       "      <td>-2.889545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.827</td>\n",
       "      <td>16.250</td>\n",
       "      <td>-2.920</td>\n",
       "      <td>-7.288</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>15.351</td>\n",
       "      <td>-10.449</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-4.933</td>\n",
       "      <td>7.777</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-3.008483</td>\n",
       "      <td>-1.854571</td>\n",
       "      <td>-2.893859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.797</td>\n",
       "      <td>16.250</td>\n",
       "      <td>-2.920</td>\n",
       "      <td>-7.222</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>14.188</td>\n",
       "      <td>-10.516</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-4.860</td>\n",
       "      <td>7.727</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-3.088857</td>\n",
       "      <td>-1.917965</td>\n",
       "      <td>-2.752764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4.737</td>\n",
       "      <td>16.250</td>\n",
       "      <td>-2.830</td>\n",
       "      <td>-7.188</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>14.048</td>\n",
       "      <td>-10.659</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-4.933</td>\n",
       "      <td>7.677</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-3.212438</td>\n",
       "      <td>-1.820224</td>\n",
       "      <td>-2.834904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-4.900</td>\n",
       "      <td>16.250</td>\n",
       "      <td>-2.890</td>\n",
       "      <td>-7.188</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>14.014</td>\n",
       "      <td>-10.659</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>-4.430</td>\n",
       "      <td>7.627</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-3.306377</td>\n",
       "      <td>-1.653918</td>\n",
       "      <td>-2.872736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1      V2     V3     V4     V5      V6      V7    V8     V9    V10  \\\n",
       "0 -5.327  12.250 -3.294 -7.855 -1.196  13.824 -10.249 -3.04 -5.170  8.077   \n",
       "1 -5.267  12.916 -3.220 -7.788 -1.196  14.424 -10.249 -3.04 -4.970  8.027   \n",
       "2 -5.127  13.583 -3.130 -7.658 -1.196  15.081 -10.359 -3.04 -4.830  7.977   \n",
       "3 -5.060  14.250 -3.130 -7.532 -1.196  14.961 -10.359 -3.04 -4.830  7.927   \n",
       "4 -4.967  14.916 -3.094 -7.462 -1.196  15.454 -10.359 -3.04 -4.970  7.877   \n",
       "5 -4.967  15.583 -3.020 -7.388 -1.196  15.284 -10.419 -3.04 -4.860  7.827   \n",
       "6 -4.827  16.250 -2.920 -7.288 -1.196  15.351 -10.449 -3.04 -4.933  7.777   \n",
       "7 -4.797  16.250 -2.920 -7.222 -1.196  14.188 -10.516 -3.04 -4.860  7.727   \n",
       "8 -4.737  16.250 -2.830 -7.188 -1.196  14.048 -10.659 -3.04 -4.933  7.677   \n",
       "9 -4.900  16.250 -2.890 -7.188 -1.196  14.014 -10.659 -3.04 -4.430  7.627   \n",
       "\n",
       "   ...    Fri    Mon    Sat    Sun    Thu   Tue    Wed      PCA1      PCA2  \\\n",
       "0  ...  False  False  False  False  False  True  False -2.616525 -2.341176   \n",
       "1  ...  False  False  False  False  False  True  False -2.691167 -2.187795   \n",
       "2  ...  False  False  False  False  False  True  False -2.724164 -2.076864   \n",
       "3  ...  False  False  False  False  False  True  False -2.744811 -2.076954   \n",
       "4  ...  False  False  False  False  False  True  False -2.827777 -1.960836   \n",
       "5  ...  False  False  False  False  False  True  False -2.914471 -1.906830   \n",
       "6  ...  False  False  False  False  False  True  False -3.008483 -1.854571   \n",
       "7  ...  False  False  False  False  False  True  False -3.088857 -1.917965   \n",
       "8  ...  False  False  False  False  False  True  False -3.212438 -1.820224   \n",
       "9  ...  False  False  False  False  False  True  False -3.306377 -1.653918   \n",
       "\n",
       "       PCA3  \n",
       "0 -3.016174  \n",
       "1 -3.000616  \n",
       "2 -2.954282  \n",
       "3 -2.864929  \n",
       "4 -2.942832  \n",
       "5 -2.889545  \n",
       "6 -2.893859  \n",
       "7 -2.752764  \n",
       "8 -2.834904  \n",
       "9 -2.872736  \n",
       "\n",
       "[10 rows x 98 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('./train.csv')\n",
    "\n",
    "# yymm 컬럼을 날짜 형식으로 변환 (연도는 임의로 설정)\n",
    "train['yymm'] = pd.to_datetime('2024' + train['yymm'], format='%Y%m%d %H:%M')\n",
    "\n",
    "# day, hour, minute, weekday 컬럼 생성\n",
    "day = train['yymm'].dt.day\n",
    "day_dummies = pd.get_dummies(day, prefix='day')\n",
    "\n",
    "hour = train['yymm'].dt.hour\n",
    "hour_dummies = pd.get_dummies(hour, prefix='hour')\n",
    "\n",
    "minute = train['yymm'].dt.minute\n",
    "minute_dummies = pd.get_dummies(minute, prefix='minute')\n",
    "\n",
    "# weekday 컬럼 생성\n",
    "weekday = day % 7\n",
    "weekday = weekday.map({0:'Mon', 1:'Tue', 2:'Wed', 3:'Thu', 4:'Fri', 5:'Sat', 6:'Sun'})\n",
    "weekday_dummies = pd.get_dummies(weekday)\n",
    "\n",
    "# PCA 피처 생성\n",
    "features = train.loc[:, 'V1':'V26'] # V1 ~ V26 컬럼 선택\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features) # 피처 표준화\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_features = pca.fit_transform(features) # PCA 피처 생성\n",
    "\n",
    "# 생성된 주성분을 DataFrame으로 변환\n",
    "pca_columns = ['PCA1', 'PCA2', 'PCA3']\n",
    "pca_df = pd.DataFrame(pca_features, columns=pca_columns)\n",
    "\n",
    "# 원본 데이터와 PCA 피처 결합\n",
    "train = pd.concat([train, day_dummies, hour_dummies, minute_dummies, weekday_dummies, pca_df], axis=1)\n",
    "\n",
    "# yymm 컬럼 삭제\n",
    "train.drop('yymm', axis=1, inplace=True)\n",
    "\n",
    "# 결과 출력\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 12.702331197553068\n",
      "Ridge: 12.698160106760502\n",
      "Lasso: 12.580224346550702\n",
      "ElasticNet: 12.582955143638385\n",
      "SVR: 12.56434179957121\n",
      "Gradient Boosting: 12.695622332027604\n",
      "Random Forest: 13.208968772774359\n",
      "XGBoost: 14.024569050620073\n",
      "LightGBM: 13.254466529819197\n",
      "Decision Tree: 16.934163402564103\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "# 데이터 분할\n",
    "X = train.drop('Target', axis=1)    # Target을 제외한 모든 컬럼을 X로 지정\n",
    "y = train['Target']                 # Target 컬럼을 y로 지정\n",
    "\n",
    "# train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "    'LightGBM': LGBMRegressor(random_state=42, verbose=-1),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# MAE를 평가 기준으로 사용하기 위해 scorer 정의\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# 각 모델에 대해 학습 및 5-fold 교차검증 수행\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=mae_scorer)\n",
    "    print(f'{model_name}: {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression best score: 12.491249180919453, num_features: 26, best features: ['hour_17', 'day_28', 'day_29', 'V7', 'day_20', 'day_22', 'day_3', 'hour_14', 'minute_10', 'Mon', 'day_30', 'hour_12', 'V17', 'hour_22', 'day_24', 'Wed', 'hour_11', 'V10', 'hour_7', 'day_21', 'day_16', 'day_4', 'V4', 'hour_23', 'minute_30', 'hour_13']\n",
      "Ridge best score: 12.490641913362998, num_features: 28, best features: ['hour_17', 'day_28', 'day_29', 'V7', 'day_20', 'day_22', 'day_3', 'hour_14', 'minute_10', 'Mon', 'day_30', 'hour_12', 'V17', 'hour_22', 'day_24', 'Wed', 'hour_11', 'V10', 'hour_7', 'day_21', 'day_16', 'day_4', 'V4', 'hour_23', 'minute_30', 'hour_13', 'hour_20', 'hour_16']\n",
      "Lasso best score: 12.535082495159886, num_features: 23, best features: ['hour_17', 'day_28', 'day_29', 'V7', 'day_20', 'day_22', 'day_3', 'hour_14', 'minute_10', 'Mon', 'day_30', 'hour_12', 'V17', 'hour_22', 'day_24', 'Wed', 'hour_11', 'V10', 'hour_7', 'day_21', 'day_16', 'day_4', 'V4']\n",
      "ElasticNet best score: 12.52996843930851, num_features: 23, best features: ['hour_17', 'day_28', 'day_29', 'V7', 'day_20', 'day_22', 'day_3', 'hour_14', 'minute_10', 'Mon', 'day_30', 'hour_12', 'V17', 'hour_22', 'day_24', 'Wed', 'hour_11', 'V10', 'hour_7', 'day_21', 'day_16', 'day_4', 'V4']\n",
      "SVR best score: 12.52871005252591, num_features: 1, best features: ['hour_17']\n",
      "Gradient Boosting best score: 12.526971033624697, num_features: 2, best features: ['hour_17', 'day_28']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "# 데이터 분할\n",
    "X = train.drop('Target', axis=1)  # Target 컬럼 제외\n",
    "y = train['Target']  # Target 컬럼\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# MAE를 평가 기준으로 사용하기 위해 scorer 정의\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# SelectKBest로 K-최고 특성 선택\n",
    "test = SelectKBest(score_func=f_regression, k=X.shape[1])\n",
    "fit = test.fit(X, y)\n",
    "\n",
    "# 선택된 특성들의 인덱스를 내림차순으로 정렬\n",
    "sorted_columns = np.argsort(fit.scores_)[::-1]\n",
    "\n",
    "# 각 모델에 대해 최적의 특성 선택\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    # 최적의 특성을 찾기 위한 변수 초기화\n",
    "    best_score = float('inf')\n",
    "    best_features = []\n",
    "\n",
    "    # 최적의 특성 선택\n",
    "    for i in range(1, X.shape[1] + 1):\n",
    "        # 선택된 feature들의 인덱스\n",
    "        fs = sorted_columns[:i]\n",
    "\n",
    "        # 선택된 feature만 선택 (Pandas DataFrame에서 iloc 사용)\n",
    "        X_selected = X.iloc[:, fs]\n",
    "        \n",
    "        # 선택된 feature들의 이름\n",
    "        selected_feature_names = X.columns[fs].tolist()\n",
    "        \n",
    "        # 교차 검증\n",
    "        mae = cross_val_score(model, X_selected, y, cv=5, scoring=mae_scorer).mean()\n",
    "\n",
    "        # 가장 성능이 좋은 MAE 및 feature를 저장\n",
    "        if mae < best_score:\n",
    "            best_score = mae\n",
    "            best_features = selected_feature_names\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} best score: {best_score}, num_features: {len(best_features)}, best features: {best_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression best score: 12.507142870053295, best features: ['V17', 'hour_11', 'hour_17', 'minute_10', 'PCA3']\n",
      "Ridge best score: 12.50727753935644, best features: ['V17', 'hour_11', 'hour_17', 'minute_10', 'PCA3']\n",
      "Lasso best score: 12.534578335004287, best features: ['V1', 'V3', 'V5', 'V10', 'V17']\n",
      "ElasticNet best score: 12.528527107451348, best features: ['V1', 'V8', 'V10', 'V17', 'V25']\n",
      "SVR best score: 12.522103727033684, best features: ['day_16', 'day_22', 'day_30', 'hour_11', 'hour_22']\n",
      "Gradient Boosting best score: 12.498082945702834, best features: ['hour_5', 'hour_7', 'hour_11', 'hour_17', 'Sat']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "# 데이터 분할\n",
    "X = train.drop('Target', axis=1)  # Target 컬럼 제외\n",
    "y = train['Target']  # Target 컬럼\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# MAE를 평가 기준으로 사용하기 위해 scorer 정의\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# 각 모델에 대해 최적의 특성 선택\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    # 최적의 특성을 찾기 위한 변수 초기화\n",
    "    best_score = float('inf')\n",
    "    best_features = []\n",
    "\n",
    "    # 최적의 특성 선택\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=5, direction='forward')\n",
    "    fit = sfs.fit(X, y)\n",
    "\n",
    "    # 선택된 피처\n",
    "    fs = X.columns[fit.support_].tolist()\n",
    "\n",
    "    # 선택된 feature 데이터프레임 생성\n",
    "    X_selected = X.iloc[:, fit.get_support()]\n",
    "\n",
    "    # 교차 검증\n",
    "    mae = cross_val_score(model, X_selected, y, cv=5, scoring=mae_scorer).mean()\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f'{model_name} best score: {mae}, best features: {fs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression best score: 12.489278598979428, best features: ['V17', 'V26', 'hour_7', 'hour_11', 'hour_13', 'hour_17', 'hour_22', 'minute_10', 'Wed', 'PCA3']\n",
      "Ridge best score: 12.489479345807295, best features: ['V17', 'V26', 'hour_7', 'hour_11', 'hour_13', 'hour_17', 'hour_22', 'minute_10', 'Wed', 'PCA3']\n",
      "Lasso best score: 12.534578335004287, best features: ['V1', 'V3', 'V5', 'V8', 'V9', 'V10', 'V12', 'V13', 'V14', 'V17']\n",
      "ElasticNet best score: 12.528527107451348, best features: ['V1', 'V3', 'V5', 'V8', 'V9', 'V10', 'V12', 'V13', 'V17', 'V25']\n",
      "SVR best score: 12.47460979363962, best features: ['day_14', 'day_16', 'day_22', 'day_24', 'day_30', 'hour_11', 'hour_17', 'hour_18', 'hour_22', 'Mon']\n",
      "Gradient Boosting best score: 12.474189750551032, best features: ['day_3', 'hour_5', 'hour_7', 'hour_11', 'hour_12', 'hour_13', 'hour_17', 'hour_19', 'Mon', 'Sat']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "# 데이터 분할\n",
    "X = train.drop('Target', axis=1)  # Target 컬럼 제외\n",
    "y = train['Target']  # Target 컬럼\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# MAE를 평가 기준으로 사용하기 위해 scorer 정의\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# 각 모델에 대해 최적의 특성 선택\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    # 최적의 특성을 찾기 위한 변수 초기화\n",
    "    best_score = float('inf')\n",
    "    best_features = []\n",
    "\n",
    "    # 최적의 특성 선택\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=10, direction='forward')\n",
    "    fit = sfs.fit(X, y)\n",
    "\n",
    "    # 선택된 피처\n",
    "    fs = X.columns[fit.support_].tolist()\n",
    "\n",
    "    # 선택된 feature 데이터프레임 생성\n",
    "    X_selected = X.iloc[:, fit.get_support()]\n",
    "\n",
    "    # 교차 검증\n",
    "    mae = cross_val_score(model, X_selected, y, cv=5, scoring=mae_scorer).mean()\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f'{model_name} best score: {mae}, best features: {fs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression best score: 12.486743268065808, best features: ['V17', 'V26', 'day_13', 'day_18', 'day_24', 'day_30', 'hour_7', 'hour_11', 'hour_13', 'hour_17', 'hour_22', 'minute_10', 'minute_30', 'Wed', 'PCA3']\n",
      "Ridge best score: 12.486972738196066, best features: ['V17', 'V26', 'day_13', 'day_18', 'day_24', 'day_30', 'hour_7', 'hour_11', 'hour_13', 'hour_17', 'hour_22', 'minute_10', 'minute_30', 'Wed', 'PCA3']\n",
      "Lasso best score: 12.534578335004287, best features: ['V1', 'V3', 'V5', 'V8', 'V9', 'V10', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20']\n",
      "ElasticNet best score: 12.528527107451348, best features: ['V1', 'V3', 'V5', 'V8', 'V9', 'V10', 'V12', 'V13', 'V15', 'V16', 'V17', 'V18', 'V19', 'V24', 'V25']\n",
      "SVR best score: 12.459366779792328, best features: ['day_7', 'day_11', 'day_14', 'day_16', 'day_22', 'day_24', 'day_27', 'day_30', 'day_31', 'hour_10', 'hour_11', 'hour_17', 'hour_18', 'hour_22', 'Mon']\n",
      "Gradient Boosting best score: 12.471963236363806, best features: ['day_2', 'day_3', 'day_8', 'day_22', 'day_30', 'hour_5', 'hour_7', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_17', 'hour_19', 'Mon', 'Sat']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "# 데이터 분할\n",
    "X = train.drop('Target', axis=1)  # Target 컬럼 제외\n",
    "y = train['Target']  # Target 컬럼\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# MAE를 평가 기준으로 사용하기 위해 scorer 정의\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# 각 모델에 대해 최적의 특성 선택\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    # 최적의 특성을 찾기 위한 변수 초기화\n",
    "    best_score = float('inf')\n",
    "    best_features = []\n",
    "\n",
    "    # 최적의 특성 선택\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=15, direction='forward')\n",
    "    fit = sfs.fit(X, y)\n",
    "\n",
    "    # 선택된 피처\n",
    "    fs = X.columns[fit.support_].tolist()\n",
    "\n",
    "    # 선택된 feature 데이터프레임 생성\n",
    "    X_selected = X.iloc[:, fit.get_support()]\n",
    "\n",
    "    # 교차 검증\n",
    "    mae = cross_val_score(model, X_selected, y, cv=5, scoring=mae_scorer).mean()\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f'{model_name} best score: {mae}, best features: {fs}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression score: 12.520577531700535, selected features: ['day_3', 'day_20', 'day_22', 'hour_14', 'hour_17']\n",
      "Ridge score: 12.5209753319046, selected features: ['day_3', 'day_13', 'day_22', 'hour_14', 'hour_17']\n",
      "Lasso score: 12.53489854284295, selected features: ['V2', 'V4', 'V7', 'V10', 'V17']\n",
      "ElasticNet score: 12.530659655893988, selected features: ['V4', 'V7', 'V10', 'V17', 'V25']\n",
      "Gradient Boosting score: 12.707682365925155, selected features: ['V3', 'V6', 'V25', 'PCA2', 'PCA3']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "# 데이터 분할\n",
    "X = train.drop('Target', axis=1)  # Target 컬럼 제외\n",
    "y = train['Target']  # Target 컬럼\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# MAE를 평가 기준으로 사용하기 위해 scorer 정의\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# RFE를 사용하여 feature selection\n",
    "for model_name, model in models.items():\n",
    "    rfe = RFE(model, n_features_to_select=5)\n",
    "    fit = rfe.fit(X, y)\n",
    "\n",
    "    fs = X.columns[fit.support_].tolist()\n",
    "    X_selected = X.iloc[:, fit.get_support()]\n",
    "\n",
    "    # 선택된 feature로 cross-validation 수행\n",
    "    score = cross_val_score(model, X_selected, y, cv=5, scoring=mae_scorer)\n",
    "\n",
    "    print(f'{model_name} score: {score.mean()}, selected features: {fs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression score: 12.510263323509992, selected features: ['day_3', 'day_6', 'day_14', 'day_20', 'day_22', 'hour_11', 'hour_14', 'hour_17', 'hour_22', 'Mon']\n",
      "Ridge score: 12.509509814234656, selected features: ['day_3', 'day_13', 'day_14', 'day_22', 'day_27', 'hour_14', 'hour_17', 'hour_22', 'Mon', 'Sun']\n",
      "Lasso score: 12.542847276969237, selected features: ['V2', 'V4', 'V7', 'V10', 'V11', 'V17', 'V21', 'PCA1', 'PCA2', 'PCA3']\n",
      "ElasticNet score: 12.538953353611754, selected features: ['V2', 'V4', 'V7', 'V10', 'V11', 'V17', 'V21', 'V25', 'V26', 'day_2']\n",
      "Gradient Boosting score: 12.628751710566949, selected features: ['V3', 'V6', 'V7', 'V16', 'V20', 'V22', 'V24', 'V25', 'PCA2', 'PCA3']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "# 데이터 분할\n",
    "X = train.drop('Target', axis=1)  # Target 컬럼 제외\n",
    "y = train['Target']  # Target 컬럼\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# MAE를 평가 기준으로 사용하기 위해 scorer 정의\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# RFE를 사용하여 feature selection\n",
    "for model_name, model in models.items():\n",
    "    rfe = RFE(model, n_features_to_select=10)\n",
    "    fit = rfe.fit(X, y)\n",
    "\n",
    "    fs = X.columns[fit.support_].tolist()\n",
    "    X_selected = X.iloc[:, fit.get_support()]\n",
    "\n",
    "    # 선택된 feature로 cross-validation 수행\n",
    "    score = cross_val_score(model, X_selected, y, cv=5, scoring=mae_scorer)\n",
    "\n",
    "    print(f'{model_name} score: {score.mean()}, selected features: {fs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression score: 12.520775014211157, selected features: ['day_3', 'day_6', 'day_14', 'day_15', 'day_18', 'day_20', 'day_22', 'day_30', 'hour_11', 'hour_12', 'hour_14', 'hour_17', 'hour_22', 'Mon', 'Tue']\n",
      "Ridge score: 12.511681929062489, selected features: ['day_3', 'day_13', 'day_14', 'day_15', 'day_18', 'day_22', 'day_27', 'hour_11', 'hour_12', 'hour_14', 'hour_17', 'hour_22', 'Mon', 'Sun', 'Tue']\n",
      "Lasso score: 12.542847276969237, selected features: ['V2', 'V4', 'V7', 'V10', 'V11', 'V17', 'V21', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed', 'PCA1', 'PCA2', 'PCA3']\n",
      "ElasticNet score: 12.538953353611754, selected features: ['V2', 'V4', 'V7', 'V10', 'V11', 'V17', 'V21', 'V25', 'V26', 'day_1', 'day_2', 'day_3', 'day_4', 'day_5', 'day_6']\n",
      "Gradient Boosting score: 12.637897085150147, selected features: ['V3', 'V6', 'V7', 'V9', 'V15', 'V16', 'V17', 'V18', 'V20', 'V21', 'V22', 'V24', 'V25', 'PCA2', 'PCA3']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "# 데이터 분할\n",
    "X = train.drop('Target', axis=1)  # Target 컬럼 제외\n",
    "y = train['Target']  # Target 컬럼\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# MAE를 평가 기준으로 사용하기 위해 scorer 정의\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# RFE를 사용하여 feature selection\n",
    "for model_name, model in models.items():\n",
    "    rfe = RFE(model, n_features_to_select=15)\n",
    "    fit = rfe.fit(X, y)\n",
    "\n",
    "    fs = X.columns[fit.support_].tolist()\n",
    "    X_selected = X.iloc[:, fit.get_support()]\n",
    "\n",
    "    # 선택된 feature로 cross-validation 수행\n",
    "    score = cross_val_score(model, X_selected, y, cv=5, scoring=mae_scorer)\n",
    "\n",
    "    print(f'{model_name} score: {score.mean()}, selected features: {fs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
